## Introduction
This repository contains code for my Master thesis and is based on the code found in the [MT3 repository](https://github.com/JulianoLagana/MT3/).

The main contributions that differentiate the MT3v3 from the two previous versions are detailed in the thesis (link coming)

A pretrained MT3v3 architecture can be found here.

## How to use
Using the pretrained model, the MT3v3 can be loaded using code found in the `src/load_model.py` file.

To evaluate the GOSPA performance of the MT3v3, code found in the `src/evaluate_model.py` can be used.

If you wish to simply inspect an autogenerated scenario, you may use code from the `src/plot_scenario.py`


## Train the MT3v3
Start training by running the `training.py` script. Example usage:

```
src/training.py -tp configs/params/data_generator.yaml -mp configs/models/mt3v3.yaml
```

Training hyperparameters such as batch size, learning rate, checkpoint interval, etc, are found in the file `configs/models/mt3v3.yaml`, while the parameters related to scenario generation are found in `configs/params/data_generator.yaml`. The flag `--continue_training_from` can be used to start training from an existing MT3v3 network.


